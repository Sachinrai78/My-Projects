# -*- coding: utf-8 -*-
"""My 45 DataSets .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KYhhuMXM-MWAXYBbZDH_r7KgzUFCOI4Z

#1.Graduationrate
"""

import pandas as pd
import numpy as np

from google.colab import files
files.upload()

df=pd.read_csv("graduation_rate.csv")
df

from sklearn.preprocessing import MinMaxScaler,OrdinalEncoder
from sklearn.linear_model import LinearRegression , LogisticRegression

X=df.iloc[:,:-1]
y=df.iloc[:,-1]

oe=OrdinalEncoder()
OE=oe.fit_transform(df[["parental level of education"]])
OE

sc=MinMaxScaler()
scaled=sc.fit_transform(df[["ACT composite score","SAT total score","parental income","high school gpa","college gpa","years to graduate"]])
scaled

X=np.hstack((OE,scaled))

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)

model=LinearRegression()
model.fit(X_train, y_train)
model.score(X_test,y_test)

"""#2 DS salaries"""

from google.colab import files
files.upload()

df=pd.read_csv("ds_salaries.csv")
df

X=df.iloc[:,:-1]
y=df.iloc[:,-1]

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0,stratify=y)

from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder , MinMaxScaler
from sklearn.neighbors import KNeighborsClassifier

from sklearn.compose import ColumnTransformer
transformer1=ColumnTransformer(transformers=[
 ("Encoding Categorical Values",OneHotEncoder(drop='first',sparse=False),["work_year","salary_currency"]),
 ("Scaling",MinMaxScaler(),["salary",	"salary_in_usd","remote_ratio"]),
 ("Ordinal Encoding",OrdinalEncoder(),["employment_type","experience_level"]),
])
model=KNeighborsClassifier()

transformer1

df.corr()

dummy=transformer1.fit_transform(df)
dummy

# Creating Pipeline
pipe = Pipeline([
    ('Transformer 1', transformer1),
])

pipe

X_train_transformed = pipe.fit_transform(X_train)
model.fit(X_train_transformed, y_train)

X_test_transformed = pipe.transform(X_test)
model.score(X_test_transformed, y_test)

"""#3 Deccan Goldmines"""

from google.colab import files
files.upload()

import pandas as pd
import numpy as np

df=pd.read_csv("deccan gold mines ltd eod price.csv")
df



from sklearn.impute import SimpleImputer
imputer=SimpleImputer()
impute=imputer.fit_transform(df[["Deliverable Quantity","% Deli. Qty to Traded Qty"]])
impute

dfnew=df.drop(["Spread C-O",""],axis=1)
dfnew

d=dfnew.drop(["Date","Deliverable Quantity","% Deli. Qty to Traded Qty"],axis=1)
d

X=np.hstack((d,impute))

from sklearn.decomposition import PCA
pca=PCA(n_components=2)
X_reduced=pca.fit_transform(X)
X_reduced

pd.DataFrame(X_reduced,columns=("col1","col2"))

col1=X_reduced[:,0]
col2=X_reduced[:,1]

import matplotlib.pyplot as plt
plt.scatter(col1,col2)

from sklearn.cluster import KMeans
model=KMeans(n_clusters=2)
model.fit(X)
cluster_labels=model.labels_
cluster_labels

elbow=[]
for k in range(1,30):
  model=KMeans(n_clusters=k)
  model.fit(X)
  elbow.append(model.inertia_)

import matplotlib.pyplot as plt
plt.scatter(range(1,30),elbow,color="red")
plt.plot(range(1,30),elbow,color="blue")

model=KMeans(n_clusters=3)
model.fit(X)
cluster_labels=model.labels_
cluster_labels

plt.scatter(col1[np.argwhere(cluster_labels==0)],col2[np.argwhere(cluster_labels==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_labels==1)],col2[np.argwhere(cluster_labels==1)],color="blue")
plt.scatter(col1[np.argwhere(cluster_labels==2)],col2[np.argwhere(cluster_labels==2)],color="green")

"""#4 Housing database community"""

from google.colab import files
files.upload()

import numpy as np
import pandas as pd

df=pd.read_csv('housing_database_by_community_district_1.csv')
df.head()

df.info()

dfnew=df.drop(["shape_area","shape_length","objectid","the_geom"],axis=1)
dfnew.head(50)

X=dfnew.iloc[:,:-1]
y=dfnew.iloc[:,-1]

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)

from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder,MinMaxScaler
from sklearn.impute import SimpleImputer

oe=OrdinalEncoder()
boroe=oe.fit_transform(dfnew[["boro"]])
boroe

imputer=SimpleImputer()
impute=imputer.fit_transform(dfnew[["comp2010ap","comp2010","comp2011","comp2012","comp2013","comp2014","comp2015","comp2016","comp2018","comp2019","filed","approved","permitted","withdrawn","inactive","comp2020"]])
impute

sc=MinMaxScaler()
scaled=sc.fit_transform(dfnew[["commntydst","cenunits10"]])
scaled

X=np.hstack((boroe,impute,scaled))
X

from sklearn.neighbors import KNeighborsRegressor

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)

model=KNeighborsRegressor()
model.fit(X_train,y_train)
model.score(X_test,y_test)

from sklearn.linear_model import LinearRegression, LogisticRegression
model=LinearRegression()
model.fit(X_train,y_train)
model.score(X_test,y_test)

"""#5 Housing"""

from google.colab import files
files.upload()

df=pd.read_csv("Housing.csv")
df

dfnew=df.drop(["CHAS","DIS","B","ZN"],axis=1)
dfnew

dfnew.info()

X=dfnew.iloc[:,:-1]
y=dfnew.iloc[:,-1]

from sklearn.neighbors import KNeighborsRegressor
from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.impute import SimpleImputer

imp=SimpleImputer()
imputer=imp.fit_transform(df[["INDUS","NOX","AGE","RAD","LSTAT"]])
imputer

sc=MinMaxScaler()
Scaling=sc.fit_transform(dfnew[["CRIM","RM","TAX","PTRATIO"]])
Scaling

X=np.hstack((Scaling,imputer))
X

y

sc=MinMaxScaler()
y=sc.fit_transform(df[["MEDV"]])
y

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)

model=LinearRegression()
model.fit(X_train,y_train)
model.score(X_test,y_test)

X=np.hstack((Scaling,imputer,y))
X

from sklearn.decomposition import PCA
pca=PCA(n_components=2)
X_reduced=pca.fit_transform(X)

pd.DataFrame(X_reduced,columns=("col1","col2"))

col1=X_reduced[:,0]
col2=X_reduced[:,1]

import matplotlib.pyplot as plt
plt.scatter(col1,col2)

from sklearn.cluster import KMeans
model=KMeans(n_clusters=2)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")

elbow=[]
for k in range(1,15):
  model=KMeans(n_clusters=k)
  model.fit(X)
  elbow.append(model.inertia_)

elbow

plt.plot(range(1,15),elbow,color="red")
plt.scatter(range(1,15),elbow,color="green")

model=KMeans(n_clusters=2)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")

"""#6 Canada Percapita"""

import numpy as np
import pandas as pd
from google.colab import files
files.upload()

df= pd.read_csv("canada_per_capita.csv")
df

dfnew=df.drop(["Unnamed: 2"],axis=1)
dfnew

from sklearn.decomposition import PCA
pca=PCA(n_components=2)
X_reduced=pca.fit_transform(dfnew)
X_reduced

pd.DataFrame(X_reduced,columns=("col1","col2"))

col1=X_reduced[:,0]
col2=X_reduced[:,1]

import matplotlib.pyplot as plt
plt.scatter(col1,col2)

from sklearn.cluster import KMeans
model=KMeans(n_clusters=2)
model.fit(dfnew)
cluster_labels=model.labels_
cluster_labels

plt.scatter(col1[np.argwhere(cluster_labels==1)],col2[np.argwhere(cluster_labels==1)],color='red')
plt.scatter(col1[np.argwhere(cluster_labels==0)],col2[np.argwhere(cluster_labels==0)],color='green')

error=[]
for k in range(1,45):
  model=KMeans(n_clusters=k)
  model.fit(dfnew)
  error.append(model.inertia_)

plt.plot(range(1,45),error,color="red")
plt.scatter(range(1,45),error,color="green")

model=KMeans(n_clusters=3)
model.fit(dfnew)
cluster_labels=model.labels_
cluster_labels

plt.scatter(col1[np.argwhere(cluster_labels==1)],col2[np.argwhere(cluster_labels==1)],color='red')
plt.scatter(col1[np.argwhere(cluster_labels==0)],col2[np.argwhere(cluster_labels==0)],color='green')
plt.scatter(col1[np.argwhere(cluster_labels==2)],col2[np.argwhere(cluster_labels==2)],color='blue')

"""#7 Car Prices"""

from google.colab import files
files.upload()

import numpy as np
import pandas as pd
df=pd.read_csv("carprices.csv")
df

dfnew=df.drop(["Car Model"],axis=1)
dfnew

X=dfnew.iloc[:,:-1]
y=dfnew.iloc[:,-1]

from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder, MinMaxScaler
oe=OrdinalEncoder()
Car=oe.fit_transform(df[["Car Model"]])
Car

sc=MinMaxScaler()
scaling=sc.fit_transform(dfnew[["Mileage","Sell Price($)"]])
scaling

X=np.hstack((Car,scaling))
X

oe=OrdinalEncoder()
y=oe.fit_transform(df[["Age(yrs)"]])
y

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)

from sklearn.neighbors import KNeighborsRegressor
model=KNeighborsRegressor()
model.fit(X_train,y_train)
model.score(X_test,y_test)

from sklearn.linear_model import LinearRegression
model=LinearRegression()
model.fit(X_train,y_train)
model.score(X_test,y_test)

"""#8 Customer"""

import numpy as np
import pandas as pd
from google.colab import files
files.upload()

df=pd.read_csv("Customer.csv")
df

dfnew=df.drop(["Customer ID","Customer Name","Country"],axis=1)
dfnew

X=dfnew.iloc[:,:-1]
y=dfnew.iloc[:,-1]

from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, MinMaxScaler
oe=OrdinalEncoder()
OE=oe.fit_transform(dfnew[["City","State"]])
OE

ohe=OneHotEncoder(drop='first',sparse=False)
OHE=ohe.fit_transform(dfnew[["Segment"]])
OHE

sc=MinMaxScaler()
Scaled=sc.fit_transform(dfnew[["Age","Postal Code"]])
Scaled

X=np.hstack((OE,OHE,Scaled))
X

o=OrdinalEncoder()
y=o.fit_transform(dfnew[["Region"]])
y

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)

dfnew

from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor

model=KNeighborsRegressor()
model.fit(X_train,y_train)
model.score(X_test,y_test)

"""# 9 Daily-min-temperatures"""

from google.colab import files
files.upload()

df=pd.read_csv("daily-min-temperatures.csv")
df

from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler
oe=OrdinalEncoder()
OE=oe.fit_transform(df[["Date"]])
OE

sc=MinMaxScaler()
scaled=sc.fit_transform(df[["Temp"]])
scaled

X=np.hstack((OE,scaled))
X

from sklearn.decomposition import PCA
pca=PCA(n_components=2)
X_reduced=pca.fit_transform(X)
X_reduced

pd.DataFrame(X_reduced,columns=("col1","col2"))

col1=X_reduced[:,0]
col2=X_reduced[:,1]

plt.scatter(col1,col2)

from sklearn.cluster import KMeans
model=KMeans(n_clusters=2)
model.fit(X)
cluster_labels=model.labels_
cluster_labels

plt.scatter(col1[np.argwhere(cluster_labels==0)],col2[np.argwhere(cluster_labels==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_labels==1)],col2[np.argwhere(cluster_labels==1)],color="green")

X=df.iloc[:,:-1]
y=df.iloc[:,-1]

X

from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler
oe=OrdinalEncoder()
X=oe.fit_transform(df[["Date"]])
X

sc=MinMaxScaler()
y=sc.fit_transform(df[["Temp"]])
y

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)

from sklearn.neighbors import KNeighborsRegressor,KNeighborsClassifier
model=KNeighborsRegressor()
model.fit(X_train,y_train)
model.score(X_test,y_test)

"""#10 Daily-total-female-births-CA"""

from google.colab import files
files.upload()

df=pd.read_csv("daily-total-female-births-CA.csv")
df

from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler

oe=OrdinalEncoder()
oee=oe.fit_transform(df[["date"]])
oee

sc=MinMaxScaler()
scaledtemp=sc.fit_transform(df[["births"]])
scaledtemp

X=np.hstack((oee,scaledtemp))
X

from sklearn.decomposition import PCA
pca=PCA(n_components=2)
X_reduced=pca.fit_transform(X)
X_reduced

pd.DataFrame(X_reduced,columns=('col1','col2'))

col1=X_reduced[:,0]
col2=X_reduced[:,1]

import matplotlib.pyplot as plt
plt.scatter(col1,col2)

from sklearn.cluster import KMeans
model=KMeans(n_clusters=2)
model.fit(X)
cluster=model.labels_
cluster

plt.scatter(col1[np.argwhere(cluster==0)],col2[np.argwhere(cluster==0)],color="Red")
plt.scatter(col1[np.argwhere(cluster==1)],col2[np.argwhere(cluster==1)],color="Blue")

elbow=[]
for k in range(1,15):
  model=KMeans(n_clusters=k)
  model.fit(X)
  elbow.append(model.inertia_)

elbow

plt.plot(range(1,15),elbow,color="red")
plt.scatter(range(1,15),elbow,color="blue")

model=KMeans(n_clusters=2)
model.fit(X)
cluster=model.labels_
cluster

plt.scatter(col1[np.argwhere(cluster==0)],col2[np.argwhere(cluster==0)],color="red")
plt.scatter(col1[np.argwhere(cluster==1)],col2[np.argwhere(cluster==1)],color="blue")

df

X=df.iloc[:,:-1]
y=df.iloc[:,-1]

oe=OrdinalEncoder()
X=oe.fit_transform(df[["date"]])
X

sc=MinMaxScaler()
y=sc.fit_transform(df[["births"]])
y

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)

from sklearn.neighbors import KNeighborsRegressor,KNeighborsClassifier
from sklearn.linear_model import LinearRegression,LogisticRegression
model=LinearRegression()
model.fit(X_train,y_train)
model.score(X_test,y_test)

"""#11 Hiring *"""

import pandas as pd
import numpy as np

from google.colab import files
files.upload()

df=pd.read_csv("hiring.csv")
df

X=df.iloc[:,:-1]
y=df.iloc[:,-1]

df["experience"].fillna("zero",inplace=True)

df["test_score"].fillna(0,inplace=True)

df

from sklearn.preprocessing import OrdinalEncoder,MinMaxScaler
from sklearn.impute import SimpleImputer

ohe=OrdinalEncoder()
OHE=ohe.fit_transform(df[["experience"]])
OHE

sc=MinMaxScaler()
scaled=sc.fit_transform(df[["interview_score","test_score"]])
scaled

X=np.hstack((OHE,scaled))

#sc=MinMaxScaler()
#y=sc.fit_transform(df[["salary"]])
#y

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)

from sklearn.neighbors import KNeighborsRegressor
model=KNeighborsRegressor()
model.fit(X_train,y_train)
model.score(X_test,y_test)



"""#12 House_price"""

import pandas as pd
import numpy as np

from google.colab import files
files.upload()

df=pd.read_csv("House_Price.csv")
df

A=df['n_hos_beds'].mean()
df['n_hos_beds'].fillna(A,inplace=True)

df

from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, MinMaxScaler
ohe=OneHotEncoder(drop='first',sparse=False)
OHE=ohe.fit_transform(df[["airport","waterbody","bus_ter"]])
OHE

sc=MinMaxScaler()
scaled=sc.fit_transform(df[["price","crime_rate","resid_area","air_qual","room_num","age","dist1","dist2","dist3","dist4","teachers","poor_prop","n_hos_beds","n_hot_rooms","rainfall","parks"]])
scaled

X=np.hstack((OHE,scaled))

X

from sklearn.decomposition import PCA
pca=PCA(n_components=2)
X_reduced=pca.fit_transform(X)
X_reduced

pd.DataFrame(X_reduced,columns=['col1','col2'])

col1=X_reduced[:,0]
col2=X_reduced[:,1]

import matplotlib.pyplot as plt
plt.scatter(col1,col2)

from sklearn.cluster import KMeans
model=KMeans(n_clusters=2)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")

elbow=[]
for k in range(1,15):
  model=KMeans(n_clusters=k)
  model.fit(X)
  elbow.append(model.inertia_)

elbow

plt.plot(range(1,15),elbow,color="red")
plt.scatter(range(1,15),elbow,color="green")

model=KMeans(n_clusters=3)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")
plt.scatter(col1[np.argwhere(cluster_l==2)],col2[np.argwhere(cluster_l==2)],color="blue")

"""#13 Housing  votes
---













"""

import numpy as np
import pandas as pd

from google.colab import files
files.upload()

df=pd.read_csv("house-votes-84.csv")
df

df.info()

X=df.iloc[:,:-1]
y=df.iloc[:,-1]

from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder,MinMaxScaler
ohe=OrdinalEncoder()
y=ohe.fit_transform(df[["dutyfree exports"]])
y

oe=OrdinalEncoder()
X=oe.fit_transform(df[["party","infant","water","budget","physician","salvador","religious","satellite","aid","missile","immigration","synfuels","education","superfund","crime"]])
X

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0,stratify=y)

from sklearn.neighbors import KNeighborsRegressor,KNeighborsClassifier
from sklearn.linear_model import LinearRegression,LogisticRegression
model=KNeighborsClassifier()
model.fit(X_train,y_train)
model.score(X_test,y_test)

model=LogisticRegression()
model.fit(X_train,y_train)
model.score(X_test,y_test)

df

from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder,MinMaxScaler
ohe=OneHotEncoder(drop="first",sparse=False)
OHE=ohe.fit_transform(df[["dutyfree exports"]])
OHE

oe=OrdinalEncoder()
OE=oe.fit_transform(df[["party","infant","water","budget","physician","salvador","religious","satellite","aid","missile","immigration","synfuels","education","superfund","crime"]])
OE

X=np.hstack((OE,OHE))

from sklearn.decomposition import PCA
pca=PCA(n_components=2)
X_red=pca.fit_transform(X)
X_red

pd.DataFrame(X_red,columns=("col1","col2"))

col1=X_red[:,0]
col2=X_red[:,1]

import matplotlib.pyplot as plt
plt.scatter(col1,col2)

from sklearn.cluster import KMeans
model=KMeans(n_clusters=2)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")

elbow=[]
for k in range(1,15):
  model=KMeans(n_clusters=k)
  model.fit(X)
  elbow.append(model.inertia_)

elbow

plt.plot(range(1,15),elbow,color="red")
plt.scatter(range(1,15),elbow,color="green")

model=KMeans(n_clusters=2)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")

"""# 14 Insurance Data"""

import numpy as np
import pandas as pd

from google.colab import files
files.upload()

df=pd.read_csv("insurance_data.csv")
df

X=df.iloc[:,:-1]
y=df.iloc[:,-1]

from sklearn.preprocessing import MinMaxScaler
sc=MinMaxScaler()
X=sc.fit_transform(df[["age"]])
X

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0,stratify=y)

from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
model=LogisticRegression()
model.fit(X_train,y_train)
model.score(X_test,y_test)

model=KNeighborsClassifier()
model.fit(X_train,y_train)
model.score(X_test,y_test)

"""#15 MBA Admissions *"""

import numpy as np
import pandas as pd
from google.colab import files
files.upload()

df=pd.read_csv("MBA_ADMISSIONS.csv")
df

X=df.iloc[:,:-1]
y=df.iloc[:,-1]

from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder,MinMaxScaler
ohe=OneHotEncoder(drop="first",sparse=False)
OHE=ohe.fit_transform(df[["Gender","Marital_status"]])
OHE

oe=OrdinalEncoder()
OE=oe.fit_transform(df[["STATE","Previous_Degree","Place_you_belong_to","perceived#Job#Skill"]])
OE

sc=MinMaxScaler()
scaled=sc.fit_transform(df[["pre_score","Age_in_years","Percentage_in_10_Class","Percentage_in_12_Class","Percentage_in_Under_Graduate","percentage_MBA","post_score"]])
scaled

X=np.hstack((OHE,OE,scaled))

o=OrdinalEncoder()
y=o.fit_transform(df[["Specialization"]])
y

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0,stratify=y)

from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor

model=KNeighborsClassifier()
model.fit(X_train,y_train)
model.score(X_test,y_test)

model=KNeighborsRegressor()
model.fit(X_train,y_train)
model.score(X_test,y_test)

df.info()

"""# 16 Movie"""

import pandas as pd
import numpy as np

from google.colab import files
files.upload()

df=pd.read_csv("Movie_classification.csv")
df

df.info()

X=df.iloc[:,:-1]
y=df.iloc[:,-1]

a=df["Time_taken"].mean()
df["Time_taken"].fillna(a,inplace=True)

from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder,MinMaxScaler
sc=MinMaxScaler()
scaled=sc.fit_transform(df[["Marketing expense","Production expense","Multiplex coverage","Budget","Movie_length","Lead_ Actor_Rating","Lead_Actress_rating","Director_rating","Producer_rating","Critic_rating","Trailer_views","Time_taken","Twitter_hastags","Avg_age_actors","Num_multiplex","Collection","Start_Tech_Oscar"]])
scaled

ohe=OneHotEncoder(drop="first",sparse=False)
OHE=ohe.fit_transform(df[["3D_available"]])
OHE

oe=OrdinalEncoder()
OE=oe.fit_transform(df[["Genre"]])
OE

X=np.hstack((scaled,OHE,OE))
X

from sklearn.neighbors import KNeighborsClassifier

model=KNeighborsClassifier()
model.fit(X_train,y_train)
model.score(X_test,y_test)

"""# 17 Movies Regression"""

import numpy as np
import pandas as pd
from google.colab import files
files.upload()

df=pd.read_csv("Movie_regression.csv")
df

a=df["Time_taken"].mean()
df["Time_taken"].fillna(a,inplace=True)

df

from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder,MinMaxScaler
sc=MinMaxScaler()
scaled=sc.fit_transform(df[["Marketing expense","Production expense","Multiplex coverage","Budget","Movie_length","Lead_ Actor_Rating","Lead_Actress_rating","Director_rating","Producer_rating","Critic_rating","Trailer_views","Time_taken","Twitter_hastags","Avg_age_actors","Num_multiplex","Collection"]])
scaled

ohe=OneHotEncoder(drop="first",sparse=False)
OHE=ohe.fit_transform(df[["3D_available"]])
OHE

oe=OrdinalEncoder()
OE=oe.fit_transform(df[["Genre"]])
OE

X=np.hstack((scaled,OHE,OE))
X

from sklearn.decomposition import PCA
pca=PCA(n_components=2)
X_reduced=pca.fit_transform(X)
X_reduced

pd.DataFrame(X_reduced,columns=("col1","col2"))

col1=X_reduced[:,0]
col2=X_reduced[:,1]

import matplotlib.pyplot as plt
plt.scatter(col1,col2)

from sklearn.cluster import KMeans
model=KMeans(n_clusters=2)
model.fit(X)
clabel=model.labels_
clabel

plt.scatter(col1[np.argwhere(clabel==0)],col2[np.argwhere(clabel==0)],color="red")
plt.scatter(col1[np.argwhere(clabel==1)],col2[np.argwhere(clabel==1)],color='blue')

elbow=[]
for k in range(1,15):
  model=KMeans(n_clusters=k)
  model.fit(X)
  elbow.append(model.inertia_)

elbow

plt.plot(range(1,15),elbow,color="red")
plt.scatter(range(1,15),elbow,color="green")

model=KMeans(n_clusters=2)
model.fit(X)
clabel=model.labels_
clabel

plt.scatter(col1[np.argwhere(clabel==0)],col2[np.argwhere(clabel==0)],color="red")
plt.scatter(col1[np.argwhere(clabel==1)],col2[np.argwhere(clabel==1)],color='yellow')

df

X=df.iloc[:,:-1]
y=df.iloc[:,-1]

from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder,MinMaxScaler
sc=MinMaxScaler()
scaled=sc.fit_transform(df[["Marketing expense","Production expense","Multiplex coverage","Budget","Movie_length","Lead_ Actor_Rating","Lead_Actress_rating","Director_rating","Producer_rating","Critic_rating","Trailer_views","Time_taken","Twitter_hastags","Avg_age_actors","Num_multiplex"]])
scaled

ohe=OneHotEncoder(drop="first",sparse=False)
OHE=ohe.fit_transform(df[["3D_available"]])
OHE

oe=OrdinalEncoder()
OE=oe.fit_transform(df[["Genre"]])
OE

X=np.hstack((scaled,OHE,OE))
X

sc=MinMaxScaler()
y=sc.fit_transform(df[["Collection"]])
y

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)

from sklearn.neighbors import  KNeighborsClassifier,KNeighborsRegressor
from sklearn.linear_model import LinearRegression,LogisticRegression

model=LinearRegression()
model.fit(X_train,y_train)
model.score(X_test,y_test)

"""# 18  Nih Labels *"""

import pandas as pd
import numpy as np
from google.colab import files
files.upload()

df=pd.read_csv("nih_labels.csv")
df

df=df.drop(["Patient ID"],axis=1)

df["View Position"].unique()

df.info()

X=df.iloc[:,:-1]
y=df.iloc[:,-1]

from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder,MinMaxScaler
ohe=OneHotEncoder(drop='first',sparse=False)
OHE=ohe.fit_transform(df[["View Position","Patient Gender"]])
OHE

oe=OrdinalEncoder()
OE=oe.fit_transform(df[["Image Index","Patient Age"]])
OE

sc=MinMaxScaler()
scaled=sc.fit_transform(df[["Follow-up #","Cardiomegaly","Emphysema","Effusion","Hernia","Mass","Nodule","Atelectasis","Pneumothorax","Pleural_Thickening","Pneumonia","Fibrosis","Edema","Consolidation"]])
scaled

X=np.hstack((OE,OHE,scaled))

oe=OrdinalEncoder()
y=oe.fit_transform(df[["fold"]])
y

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0,stratify=y)

from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor

model=KNeighborsClassifier()
model.fit(X_train,y_train)
model.score(X_test,y_test)

model=KNeighborsRegressor()
model.fit(X_train,y_train)
model.score(X_test,y_test)

model=LogisticRegression()
model.fit(X_train,y_train)
model.score(X_test,y_test)

df

df.corr()

from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder,MinMaxScaler
ohe=OneHotEncoder(drop='first',sparse=False)
OHE=ohe.fit_transform(df[["View Position","Patient Gender"]])
OHE

oe=OrdinalEncoder()
OE=oe.fit_transform(df[["Image Index","Patient Age","fold"]])
OE

sc=MinMaxScaler()
scaled=sc.fit_transform(df[["Follow-up #","Cardiomegaly","Emphysema","Effusion","Hernia","Mass","Nodule","Atelectasis","Pneumothorax","Pleural_Thickening","Pneumonia","Fibrosis","Edema","Consolidation"]])
scaled

X=np.hstack((OHE,OE,scaled))

from sklearn.decomposition import PCA
pca=PCA(n_components=2)
X_reduced=pca.fit_transform(X)
X_reduced

pd.DataFrame(X_reduced,columns=("col1","col2"))

col1=X_reduced[:,0]
col2=X_reduced[:,1]

import matplotlib.pyplot as plt
plt.scatter(col1,col2)

from sklearn.cluster import KMeans
model=KMeans(n_clusters=2)
model.fit(X)
clabel=model.labels_
clabel

plt.scatter(col1[np.argwhere(clabel==0)],col2[np.argwhere(clabel==0)],color="red")
plt.scatter(col1[np.argwhere(clabel==1)],col2[np.argwhere(clabel==1)],color='blue')

elbow=[]
for k in range(1,30):
  model=KMeans(n_clusters=k)
  model.fit(X)
  elbow.append(model.inertia_)

elbow

plt.plot(range(1,30),elbow,color="red")
plt.scatter(range(1,30),elbow,color="green")

model=KMeans(n_clusters=2)
model.fit(X)
clabel=model.labels_
clabel

plt.scatter(col1[np.argwhere(clabel==0)],col2[np.argwhere(clabel==0)],color="red")
plt.scatter(col1[np.argwhere(clabel==1)],col2[np.argwhere(clabel==1)],color='yellow')

"""# 19 Salaries"""

import numpy as np
import pandas as pd
from google.colab import files
files.upload()

df=pd.read_csv("salaries.csv")
df

X=df.iloc[:,:-1]
y=df.iloc[:,-1]

from sklearn.preprocessing import OneHotEncoder
ohe=OneHotEncoder(drop="first",sparse=False)
X=ohe.fit_transform(df[["company","job","degree"]])
X

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0,stratify=y)

from sklearn.linear_model import LogisticRegression

model=LogisticRegression()
model.fit(X_train,y_train)
model.score(X_test,y_test)

"""#20 Shampoo"""

import numpy as np
import pandas as pd
from google.colab import files
files.upload()

df=pd.read_csv('shampoo.csv')
df

X=df.iloc[:,:-1]
y=df.iloc[:,-1]

from sklearn.preprocessing import OrdinalEncoder,MinMaxScaler
oe=OrdinalEncoder()
X=oe.fit_transform(df[["Month"]])
X

sc=MinMaxScaler()
y=sc.fit_transform(df[["Sales"]])
y

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)

from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier
from sklearn.linear_model import LinearRegression,LogisticRegression

model=LinearRegression()
model.fit(X_train,y_train)
model.score(X_test,y_test)

df

from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder
oe=OrdinalEncoder()
OE=oe.fit_transform(df[["Month"]])
OE

sc=MinMaxScaler()
scale=sc.fit_transform(df[["Sales"]])
scale

X=np.hstack((OE,scale))

from sklearn.decomposition import PCA
pca=PCA(n_components=2)
X_red=pca.fit_transform(X)

pd.DataFrame(X_red,columns=('col1','col2'))

import matplotlib.pyplot as plt
plt.scatter(col1,col2)

from sklearn.cluster import KMeans
model=KMeans(n_clusters=2)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")

elbow=[]
for k in range(1,15):
  model=KMeans(n_clusters=k)
  model.fit(X)
  elbow.append(model.inertia_)

elbow

plt.plot(range(1,15),elbow,color="red")
plt.scatter(range(1,15),elbow,color="green")

model=KMeans(n_clusters=2)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")

"""# 21 US-airlines"""

import numpy as np
import pandas as pd
from google.colab import files
files.upload()

df=pd.read_csv("us-airlines-monthly-aircraft-miles-flown.csv")
df

X=df.iloc[:,:-1]
y=df.iloc[:,-1]

from sklearn.preprocessing import OrdinalEncoder,MinMaxScaler
oe=OrdinalEncoder()
X=oe.fit_transform(df[["Month"]])
X

sc=MinMaxScaler()
y=sc.fit_transform(df[["MilesMM"]])
y

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)

from sklearn.neighbors import KNeighborsRegressor
from sklearn.linear_model import LinearRegression

model=KNeighborsRegressor()
model.fit(X_train,y_train)
model.score(X_test,y_test)

model=LinearRegression()
model.fit(X_train,y_train)
model.score(X_test,y_test)

"""# 22 X-ray"""

import numpy as np
import pandas as pd
from google.colab import files
files.upload()

df=pd.read_csv("xrayfull.csv")
df

from sklearn.preprocessing import OrdinalEncoder,MinMaxScaler
sc=MinMaxScaler()
scaled=sc.fit_transform(df[["Cardiomegaly","Emphysema","Effusion","Hernia","Infiltration","Mass","Nodule","Atelectasis","Pneumothorax","Pleural_Thickening","Pneumonia","Fibrosis","Edema","Consolidation"]])
scaled

oe=OrdinalEncoder()
OE=oe.fit_transform(df[["Image Index"]])
OE

o=OrdinalEncoder()
y=o.fit_transform(df[["fold"]])
y

X=np.hstack((OE,scaled))

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0,stratify=y)

from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor

model=KNeighborsClassifier()
model.fit(X_train,y_train)
model.score(X_test,y_test)

model=KNeighborsRegressor()
model.fit(X_train,y_train)
model.score(X_test,y_test)

df

from sklearn.preprocessing import OrdinalEncoder,MinMaxScaler
sc=MinMaxScaler()
scaled=sc.fit_transform(df[["Cardiomegaly","Emphysema","Effusion","Hernia","Infiltration","Mass","Nodule","Atelectasis","Pneumothorax","Pleural_Thickening","Pneumonia","Fibrosis","Edema","Consolidation"]])
scaled

oe=OrdinalEncoder()
OE=oe.fit_transform(df[["Image Index","fold"]])
OE

X=np.hstack((scaled,OE))

from sklearn.decomposition import PCA
pca=PCA(n_components=2)
X_red=pca.fit_transform(X)
X_red

pd.DataFrame(X_red,columns=("col1","col2"))

col1=X_red[:,0]
col2=X_red[:,1]

import matplotlib.pyplot as plt
plt.scatter(col1,col2)

from sklearn.cluster import KMeans
model=KMeans(n_clusters=2)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")

elbow=[]
for k in range(1,15):
  model=KMeans(n_clusters=k)
  model.fit(X)
  elbow.append(model.inertia_)

elbow

plt.plot(range(1,15),elbow,color="red")
plt.scatter(range(1,15),elbow,color="green")

model=KMeans(n_clusters=3)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")
plt.scatter(col1[np.argwhere(cluster_l==2)],col2[np.argwhere(cluster_l==2)],color="BLUE")

"""# 23 Trip Advisor"""

import numpy as np
import pandas as pd

df=pd.read_csv("/content/trip advisor restaurents  10k - trip_rest_neywork_1 (1).csv")
df

df=df.drop(["Reveiw Comment","Title"],axis=1)

X=df.iloc[:,:-1]
y=df.iloc[:,-1]

from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder,MinMaxScaler
oe=OrdinalEncoder()
X=oe.fit_transform(df[["Catagory","Number of review","Popular food"]])
X

oe=OrdinalEncoder()
y=oe.fit_transform(df[["Online Order"]])
y

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)

from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor
from sklearn.linear_model import LinearRegression,LogisticRegression

model=KNeighborsClassifier()
model.fit(X_train,y_train)
model.score(X_test,y_test)

"""# 24 Imdb_movies"""

import numpy as np
import pandas as pd
df=pd.read_csv("/content/imdb_movies.csv")
df

df=df.drop(["names","crew",'date_x',"overview"],axis=1)

df

df["genre"].fillna('NaN',inplace=True)

from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder,MinMaxScaler
oe=OrdinalEncoder()
OE=oe.fit_transform(df[["genre","orig_title","status","orig_lang","country"]])
OE

#ohe=OneHotEncoder(drop='first',sparse=False)
#OHE=ohe.fit_transform(df[["country"]])
#OHE

sc=MinMaxScaler()
scaled=sc.fit_transform(df[["score","budget_x"]])
scaled

sc=MinMaxScaler()
y=sc.fit_transform(df[["revenue"]])
y

X=np.hstack((OE,scaled))
X

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)

from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor
from sklearn.linear_model import LinearRegression,LogisticRegression

model=LinearRegression()
model.fit(X_train,y_train)
model.score(X_test,y_test)

"""# 25 Compras"""

import numpy as np
import pandas as pd
from google.colab import files
files.upload()

df=pd.read_csv("Compras2022.csv")
df.head()

df=df.drop(["margen_bruto","saldo_actual"],axis=1)

df.head(2)

df.info()

a=df["precio_actual"].mean()
df["precio_actual"].fillna(a,inplace=True)

b=df["precio_nuevo"].mean()
df["precio_nuevo"].fillna(b,inplace=True)

from sklearn.preprocessing import OrdinalEncoder,OneHotEncoder, MinMaxScaler
oe=OrdinalEncoder()
OE=oe.fit_transform(df[["proveedor","fecha","tipo","descripcion","unidad","bodega","producto","cant"]])
OE

sc=MinMaxScaler()
scaled=sc.fit_transform(df[["numero","vlrunit","total_siniva","iva_tasa","valor_iva","cuenta","precio_actual","precio_nuevo"]])
scaled

X=np.hstack((OE,scaled))
X

from sklearn.decomposition import PCA
pca=PCA(n_components=2)
X_red=pca.fit_transform(X)
X_red

pd.DataFrame(X_red,columns=("col1","col2"))

col1=X_red[:,0]
col2=X_red[:,1]

import matplotlib.pyplot as plt
plt.scatter(col1,col2)

from sklearn.cluster import KMeans
model=KMeans(n_clusters=2)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")

elbow=[]
for k in range(1,15):
  model=KMeans(n_clusters=k)
  model.fit(X)
  elbow.append(model.inertia_)

elbow

plt.plot(range(1,15),elbow,color="red")
plt.scatter(range(1,15),elbow,color="green")

model=KMeans(n_clusters=2)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")



"""#26 Car Price Assignment"""

import numpy as np
import pandas as pd
from google.colab import files
files.upload()

df=pd.read_csv("CarPrice_Assignment.csv")
df

df.corr()

df=df.drop(["car_ID"],axis=1)

df

df.info()

X=df.iloc[:,:-1]
y=df.iloc[:,-1]

from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder,MinMaxScaler
from sklearn.compose import ColumnTransformer, make_column_transformer
from sklearn.linear_model import LinearRegression,LogisticRegression

transformer=make_column_transformer(
    (OrdinalEncoder(),["CarName","fueltype","aspiration","doornumber","carbody","drivewheel","enginelocation","enginetype","cylindernumber","fuelsystem"]),
    (MinMaxScaler(),["symboling","wheelbase","carlength","carwidth","carheight","curbweight","enginesize","boreratio","stroke","compressionratio","horsepower","peakrpm","citympg","highwaympg"]),remainder='passthrough'

)
model=LinearRegression()

transformer

sc=MinMaxScaler()
y=sc.fit_transform(df[["price"]])
y

X=dummy

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)

model=LinearRegression()
model.fit(X_train,y_train)
model.score(X_test,y_test)



"""# 27 Admission"""

import numpy as np
import pandas as pd
from google.colab import files
files.upload()

df=pd.read_csv("Admission.csv")
df

df=df.drop(["SlNo"],axis=1)

df.info()

df["Entrance_Test"].fillna("None",inplace=True)

X=df.iloc[:,:-1]
y=df.iloc[:,-1]

from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder,MinMaxScaler
from sklearn.compose import ColumnTransformer, make_column_transformer

transformer=make_column_transformer(
    (OneHotEncoder(drop='first'),["Gender","Board_SSC","Board_HSC","Stream_HSC","Specialization_MBA","Placement"]),
    (OrdinalEncoder(),["Course_Degree","Entrance_Test"]),
    (MinMaxScaler(),["Percent_SSC","Percent_HSC","Percent_Degree","Experience_Yrs","Percentile_ET","Percent_MBA","Marks_Communication","Marks_Projectwork","Marks_BOCA"]),remainder="passthrough"
)
model=LinearRegression()

transformer

sc=MinMaxScaler()
y=sc.fit_transform(df[["Salary"]])
y

dummy=transformer.fit_transform(X)

from sklearn.pipeline import Pipeline , make_pipeline

pipe=Pipeline([("transformer",transformer)])

pipe

X_scaled=pipe.fit_transform(X)

X=X_scaled

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)

model=LinearRegression()
model.fit(X_train,y_train)
model.score(X_test,y_test)



"""# 28 ADANIENT.NS

"""

import numpy as np
import pandas as pd

from google.colab import files
files.upload()

df=pd.read_csv("ADANIENT.NS (3).csv")
df

df.info()

df=df.drop(["Date"],axis=1)

df

X=df.iloc[:,:-1]
y=df.iloc[:,-1]

from sklearn.preprocessing import MinMaxScaler
from sklearn.impute import SimpleImputer
sc=SimpleImputer()
X=sc.fit_transform(df[["Open","High","Low","Close","Adj Close"]])
X

sc=SimpleImputer()
y=sc.fit_transform(df[["Volume"]])
y

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)

model=KNeighborsRegressor()
model.fit(X_train,y_train)
model.score(X_test,y_test)

df

from sklearn.preprocessing import MinMaxScaler
from sklearn.impute import SimpleImputer
sc=SimpleImputer()
imp=sc.fit_transform(df[["Open","High","Low","Close","Adj Close","Volume"]])
imp

sc=MinMaxScaler()
X=sc.fit_transform(imp)
X

from sklearn.decomposition import PCA
pca=PCA(n_components=2)
X_red=pca.fit_transform(X)
X_red

pd.DataFrame(X_red,columns=("col1","col2"))

col1=X_red[:,0]
col2=X_red[:,1]

import matplotlib.pyplot as plt
plt.scatter(col1,col2)

from sklearn.cluster import KMeans
model=KMeans(n_clusters=2)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")

elbow=[]
for k in range(1,15):
  model=KMeans(n_clusters=k)
  model.fit(X)
  elbow.append(model.inertia_)

elbow

plt.plot(range(1,15),elbow,color="red")
plt.scatter(range(1,15),elbow,color="green")

model=KMeans(n_clusters=2)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")

plt.plot(col1,col2)



"""#29 Cricket Centuries

"""

import numpy as np
import pandas as pd
from google.colab import files
files.upload()

df=pd.read_csv("temp.csv")
df

from sklearn.preprocessing import OrdinalEncoder,MinMaxScaler
oe=OrdinalEncoder()
OE=oe.fit_transform(df[["name"]])
OE

sc=MinMaxScaler()
scaled=sc.fit_transform(df[["Id","centuries"]])
scaled

X=np.hstack((OE,scaled))

from sklearn.decomposition import PCA
pca=PCA(n_components=2)
X_red=pca.fit_transform(X)
X_red

pd.DataFrame(X_red,columns=("col1","col2"))

col1=X_red[:,0]
col2=X_red[:,1]

import matplotlib.pyplot as plt
plt.scatter(col1,col2)

from sklearn.cluster import KMeans
model=KMeans(n_clusters=2)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")

elbow=[]
for k in range(1,5):
  model=KMeans(n_clusters=k)
  model.fit(X)
  elbow.append(model.inertia_)

elbow

plt.plot(range(1,15),elbow,color="red")
plt.scatter(range(1,15),elbow,color="green")

model=KMeans(n_clusters=5)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")
plt.scatter(col1[np.argwhere(cluster_l==2)],col2[np.argwhere(cluster_l==2)],color="blue")
plt.scatter(col1[np.argwhere(cluster_l==3)],col2[np.argwhere(cluster_l==3)],color="yellow")
plt.scatter(col1[np.argwhere(cluster_l==4)],col2[np.argwhere(cluster_l==4)],color="black")

plt.plot(col1,col2)

"""# 30 Amazon"""

import numpy as np
import pandas as pd
from google.colab import files
files.upload()

df=pd.read_csv("amazon.csv")
df

df=df.drop(["product_id","user_id","img_link","product_link","review_id","review_title","review_content"],axis=1)

df.info()

df["rating_count"].fillna('none',inplace=True)

from sklearn.preprocessing import OrdinalEncoder
oe=OrdinalEncoder()
X=oe.fit_transform(df[["product_name","category","discounted_price","discount_percentage","rating","rating_count","about_product","user_name","actual_price"]])
X

from sklearn.decomposition import PCA
pca=PCA(n_components=2)
X_red=pca.fit_transform(X)
X_red

pd.DataFrame(X_red,columns=("col1","col2"))

col1=X_red[:,0]
col2=X_red[:,1]

import matplotlib.pyplot as plt
plt.scatter(col1,col2)

from sklearn.cluster import KMeans
model=KMeans(n_clusters=2)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")

elbow=[]
for k in range(1,15):
  model=KMeans(n_clusters=k)
  model.fit(X)
  elbow.append(model.inertia_)

elbow

plt.plot(range(1,15),elbow,color="red")
plt.scatter(range(1,15),elbow,color="green")

model=KMeans(n_clusters=3)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")
plt.scatter(col1[np.argwhere(cluster_l==2)],col2[np.argwhere(cluster_l==2)],color="blue")

plt.plot(col1,col2)

"""# 31 Customer Shopping"""

import numpy as np
import pandas as pd
from google.colab import files
files.upload()

df=pd.read_csv("customer_shopping_data.csv")
df

df=df.drop(["invoice_no","customer_id","invoice_date"],axis=1)

df.info()

df

from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder,MinMaxScaler
ohe=OneHotEncoder(drop='first',sparse_output=False)
OHE=ohe.fit_transform(df[["gender"]])
OHE

oe=OrdinalEncoder()
OE=oe.fit_transform(df[["category","payment_method","shopping_mall"]])
OE

sc=MinMaxScaler()
scaled=sc.fit_transform(df[["age","quantity","price"]])
scaled

X=np.hstack((OE,OHE,scaled))
X

from sklearn.decomposition import PCA
pca=PCA(n_components=2)
X_red=pca.fit_transform(X)
X_red

pd.DataFrame(X_red,columns=("col1","col2"))

col1=X_red[:,0]
col2=X_red[:,1]

import matplotlib.pyplot as plt
plt.scatter(col1,col2)

from sklearn.cluster import KMeans
model=KMeans(n_clusters=2)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")

elbow=[]
for k in range(1,15):
  model=KMeans(n_clusters=k)
  model.fit(X)
  elbow.append(model.inertia_)

elbow

plt.plot(range(1,15),elbow,color="red")
plt.scatter(range(1,15),elbow,color="green")

model=KMeans(n_clusters=3)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")
plt.scatter(col1[np.argwhere(cluster_l==2)],col2[np.argwhere(cluster_l==2)],color="blue")

plt.plot(col1,col2)

"""# 32 Bank"""

import numpy as np
import pandas as pd
from google.colab import files
files.upload()

df=pd.read_csv("bank-full.csv")
df

df.info()

X=df.iloc[:,:-1]
y=df.iloc[:,-1]

X

y

from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder,MinMaxScaler
ohe=OneHotEncoder(drop="first",sparse=False)
OHE=ohe.fit_transform(df[["marital","education","default","housing","loan","contact","poutcome"]])
OHE

oe=OrdinalEncoder()
OE=oe.fit_transform(df[["job","month"]])
OE

sc=MinMaxScaler()
Scaled=sc.fit_transform(df[["age","balance","day","duration","campaign","pdays","previous"]])
scaled

o=OneHotEncoder(drop='first',sparse_output=False)
y=o.fit_transform(df[["Target"]])
y

X=np.hstack((OHE,OE,Scaled))
X

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0,stratify=y)

from sklearn.neighbors import KNeighborsClassifier
model=KNeighborsClassifier()
model.fit(X_train,y_train)
model.score(X_test,y_test)

df

from sklearn.compose import ColumnTransformer, make_column_transformer
transformer=make_column_transformer(
    (OneHotEncoder(drop='first',sparse_output=False),["marital","education","default","housing","loan","contact","poutcome"]),
    (OrdinalEncoder(),["job","month"]),
    (MinMaxScaler(),["age","balance","day","duration","campaign","pdays","previous"]),remainder='passthrough'
)
model=LogisticRegression()

transformer

o=OneHotEncoder(drop='first',sparse_output=False)
y=o.fit_transform(df[["Target"]])
y

dummy=transformer.fit_transform(df)

dummy

from sklearn.pipeline import Pipeline, make_pipeline
pipe=Pipeline([("Transformer",transformer)])

pipe

X=pipe.fit_transform(df)

dfnew=pd.DataFrame(X)
dfnew

model=LogisticRegression()
model.fit(X_train,y_train)
model.score(X_test,y_test)

"""# 33 PRSA_data_"""

import numpy as np
import pandas as pd

from google.colab import files
files.upload()

df=pd.read_csv("PRSA_data_2010.1.1-2014.12.31.csv")
df

df=df.drop(["No"],axis=1)

df.info()

a=df["pm2.5"].mean()
df["pm2.5"].fillna(a,inplace=True)

from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder,MinMaxScaler
oe=OneHotEncoder(drop='first',sparse=False)
OE=ohe.fit_transform(df[["cbwd"]])
OE

sc=MinMaxScaler()
Scaled=sc.fit_transform(df[["year","month","day","hour","pm2.5","DEWP","TEMP","PRES","Iws","Is","Ir"]])
Scaled

X=np.hstack((OE,Scaled))
X

from sklearn.decomposition import PCA
pca=PCA(n_components=2)
X_red=pca.fit_transform(X)
X_red

pd.DataFrame(X_red,columns=("col1","col2"))

col1=X_red[:,0]
col2=X_red[:,1]

import matplotlib.pyplot as plt
plt.scatter(col1,col2)

from sklearn.cluster import KMeans
model=KMeans(n_clusters=2)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")

elbow=[]
for k in range(1,15):
  model=KMeans(n_clusters=k)
  model.fit(X)
  elbow.append(model.inertia_)

elbow

plt.plot(range(1,15),elbow,color="red")
plt.scatter(range(1,15),elbow,color="green")

model=KMeans(n_clusters=4)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")
plt.scatter(col1[np.argwhere(cluster_l==2)],col2[np.argwhere(cluster_l==2)],color="blue")
plt.scatter(col1[np.argwhere(cluster_l==3)],col2[np.argwhere(cluster_l==3)],color="yellow")

plt.plot(col1,col2)

"""# 34 Songs"""

import pandas as pd
import numpy as np
from google.colab import files
files.upload()

df=pd.read_csv("songs.csv")
df

df.info()

from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler
oe=OrdinalEncoder()
OE=oe.fit_transform(df[["Name","Artist","Album","Lyrics"]])
OE

sc=MinMaxScaler()
scaled=sc.fit_transform(df[["Popularity"]])
scaled

X=np.hstack((OE,scaled))
X

from sklearn.decomposition import PCA
pca=PCA(n_components=2)
X_red=pca.fit_transform(X)
X_red

pd.DataFrame(X_red,columns=("col1","col2"))

col1=X_red[:,0]
col2=X_red[:,1]

import matplotlib.pyplot as plt
plt.scatter(col1,col2)

from sklearn.cluster import KMeans
model=KMeans(n_clusters=2)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")

elbow=[]
for k in range(1,15):
  model=KMeans(n_clusters=k)
  model.fit(X)
  elbow.append(model.inertia_)

elbow

plt.plot(range(1,15),elbow,color="red")
plt.scatter(range(1,15),elbow,color="green")

model=KMeans(n_clusters=3)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")
plt.scatter(col1[np.argwhere(cluster_l==2)],col2[np.argwhere(cluster_l==2)],color="blue")

plt.plot(col1,col2)

"""# 35 Cars"""

import numpy as np
import pandas as pd
from google.colab import files
files.upload()

df=pd.read_csv("car_data.csv")
df

df=df.drop(["User ID"],axis=1)

X=df.iloc[:,:-1]
y=df.iloc[:,-1]

from sklearn.preprocessing import OneHotEncoder,MinMaxScaler
ohe=OneHotEncoder(drop="first",sparse=False)
OHE=ohe.fit_transform(df[["Gender"]])
OHE

sc=MinMaxScaler()
scaled=sc.fit_transform(df[["Age","AnnualSalary"]])
scaled

X=np.hstack((OHE,scaled))

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0,stratify=y)

model=KNeighborsClassifier()
model.fit(X_train,y_train)
model.score(X_test,y_test)

"""# 36 Facebook"""

import numpy as np
import pandas as pd
from google.colab import files
files.upload()

df=pd.read_csv("facebook.csv")
df

from sklearn.preprocessing import OrdinalEncoder,MinMaxScaler
oe=OrdinalEncoder()
OE=oe.fit_transform(df[["Datetime","Text","Username"]])
OE

sc=MinMaxScaler()
scaled=sc.fit_transform(df[["Tweet Id"]])
scaled

X=np.hstack((OE,scaled))
X

from sklearn.decomposition import PCA
pca=PCA(n_components=2)
X_red=pca.fit_transform(X)
X_red

pd.DataFrame(X_red,columns=("col1","col2"))

col1=X_red[:,0]
col2=X_red[:,1]

import matplotlib.pyplot as plt
plt.scatter(col1,col2)

from sklearn.cluster import KMeans
model=KMeans(n_clusters=2)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")

elbow=[]
for k in range(1,15):
  model=KMeans(n_clusters=k)
  model.fit(X)
  elbow.append(model.inertia_)

elbow

plt.plot(range(1,15),elbow,color="red")
plt.scatter(range(1,15),elbow,color="green")

model=KMeans(n_clusters=3)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")
plt.scatter(col1[np.argwhere(cluster_l==2)],col2[np.argwhere(cluster_l==2)],color="blue")

plt.plot(col1,col2)

"""# 37 Online Shopper"""

from google.colab import files
files.upload()

df=pd.read_csv("Clus_OnlineShoppersIntention.csv")
df

df=df.drop(["BounceRates","ExitRates","PageValues","SpecialDay","Weekend"],axis=1)

df

from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, MinMaxScaler
oe=OrdinalEncoder()
OE=oe.fit_transform(df[["Month","VisitorType"]])
OE

sc=MinMaxScaler()
scaled=sc.fit_transform(df[["Administrative","Administrative_Duration","Informational","Informational_Duration","ProductRelated","ProductRelated_Duration","OperatingSystems","Browser","Region","TrafficType"]])
scaled

ohe=OneHotEncoder(drop="first",sparse_output=False)
OHE=ohe.fit_transform(df[["Revenue"]])
OHE

X=np.hstack((OE,scaled,OHE))
X

from sklearn.decomposition import PCA
pca=PCA(n_components=2)
X_red=pca.fit_transform(X)
X_red

pd.DataFrame(X_red,columns=("col1","col2"))

col1=X_red[:,0]
col2=X_red[:,1]

import matplotlib.pyplot as plt
plt.scatter(col1,col2)

from sklearn.cluster import KMeans
model=KMeans(n_clusters=2)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")

elbow=[]
for k in range(1,15):
  model=KMeans(n_clusters=k)
  model.fit(X)
  elbow.append(model.inertia_)

elbow

plt.plot(range(1,15),elbow,color="red")
plt.scatter(range(1,15),elbow,color="green")

model=KMeans(n_clusters=3)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")
plt.scatter(col1[np.argwhere(cluster_l==2)],col2[np.argwhere(cluster_l==2)],color="blue")

plt.plot(col1,col2)

"""# 38 Reg_EnergyData"""

from google.colab import files
files.upload()

import numpy as np
import pandas as pd

df=pd.read_csv("Reg_EnergyData.csv")
df.head(5)

df=df.drop(["date","rv1","rv2","Visibility","Press_mm_hg","Appliances","lights"],axis=1)

from sklearn.preprocessing import MinMaxScaler
mms=MinMaxScaler()
X=mms.fit_transform(df[["T1","RH_1","T2","RH_2","T3","RH_3","T4","RH_4","T5","RH_5","T6","RH_6","T7","RH_7","T8","RH_8","T9","RH_9","T_out","RH_out","Windspeed","Tdewpoint"]])
X

from sklearn.decomposition import PCA
pca=PCA(n_components=2)
X_red=pca.fit_transform(X)
X_red

pd.DataFrame(X_red,columns=("col1","col2"))

col1=X_red[:,0]
col2=X_red[:,1]

import matplotlib.pyplot as plt
plt.scatter(col1,col2)

from sklearn.cluster import KMeans
model=KMeans(n_clusters=2)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")

elbow=[]
for k in range(1,15):
  model=KMeans(n_clusters=k)
  model.fit(X)
  elbow.append(model.inertia_)

elbow

plt.plot(range(1,15),elbow,color="red")
plt.scatter(range(1,15),elbow,color="green")

model=KMeans(n_clusters=3)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")
plt.scatter(col1[np.argwhere(cluster_l==2)],col2[np.argwhere(cluster_l==2)],color="blue")

plt.plot(col1,col2)

"""#39 Sonar"""

from google.colab import files
files.upload()

import numpy as np
import pandas as pd

df=pd.read_csv("Class_Sonar.csv")
df

X=df.iloc[:,:-1]
y=df.iloc[:,-1]

from sklearn.preprocessing import MinMaxScaler,OneHotEncoder
sc=MinMaxScaler()
X=sc.fit_transform(df[['Ang1','Ang2','Ang3','Ang4','Ang5','Ang6','Ang7','Ang8','Ang9','Ang10','Ang11','Ang12','Ang13','Ang14','Ang15','Ang16','Ang17','Ang18','Ang19','Ang20','Ang21','Ang22','Ang23','Ang24','Ang25','Ang26','Ang27','Ang28','Ang29','Ang30','Ang31','Ang32','Ang33','Ang34','Ang35','Ang36','Ang37','Ang38','Ang39','Ang40','Ang41','Ang42','Ang43','Ang44','Ang45','Ang46','Ang47','Ang48','Ang49','Ang50','Ang51','Ang52','Ang53','Ang54','Ang55','Ang56','Ang57','Ang58','Ang59']])
X

ohe=OneHotEncoder(drop='first',sparse_output=False)
y=ohe.fit_transform(df[["Class"]])
y

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0,stratify=y)

from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor
from sklearn.linear_model import LinearRegression,LogisticRegression
model=KNeighborsClassifier()
model.fit(X_train,y_train)
model.score(X_test,y_test)

"""#40 BuddyMove"""

import numpy as np
import pandas as pd
from google.colab import files
files.upload()

df=pd.read_csv("Clus_BuddyMove.csv")
df

df=df.drop(["User Id"],axis=1)

df.info()

from sklearn.preprocessing import MinMaxScaler
sc=MinMaxScaler()
X=sc.fit_transform(df[["Sports","Religious","Nature","Theatre","Shopping","Picnic"]])
X

from sklearn.decomposition import PCA
pca=PCA(n_components=2)
X_red=pca.fit_transform(X)
X_red

pd.DataFrame(X_red,columns=("col1","col2"))

col1=X_red[:,0]
col2=X_red[:,1]

import matplotlib.pyplot as plt
plt.scatter(col1,col2)

from sklearn.cluster import KMeans
model=KMeans(n_clusters=2)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")

elbow=[]
for k in range(1,15):
  model=KMeans(n_clusters=k)
  model.fit(X)
  elbow.append(model.inertia_)

elbow

plt.plot(range(1,15),elbow,color="red")
plt.scatter(range(1,15),elbow,color="green")

model=KMeans(n_clusters=3)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")
plt.scatter(col1[np.argwhere(cluster_l==2)],col2[np.argwhere(cluster_l==2)],color="blue")

plt.plot(col1,col2)

"""#41 Seeds"""

import pandas as pd
import numpy as np
from google.colab import files
files.upload()

df=pd.read_csv("Class_Seeds.csv")
df

X=df.iloc[:,:-1]
y=df.iloc[:,-1]

from sklearn.preprocessing import OneHotEncoder,MinMaxScaler
sc=MinMaxScaler()
X=sc.fit_transform(df[["Area","Perimeter","Compactness","KernelLength","KernelWidth","AsymCoeff","KernelGrov_Length"]])
X

ohe=OneHotEncoder(drop='first',sparse_output=False)
y=ohe.fit_transform(df[["Class"]])
y

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0,stratify=y)

from sklearn.neighbors import KNeighborsClassifier

model=KNeighborsClassifier()
model.fit(X_train,y_train)
model.score(X_test,y_test)

"""#42 Ionosphere"""

from google.colab import files
files.upload()

import numpy as np
import pandas as pd
df=pd.read_csv("Class_Ionosphere.csv")
df

df=df.drop(["RRD2"],axis=1)

df.info()

X=df.iloc[:,:-1]
y=df.iloc[:,-1]

from sklearn.preprocessing import OneHotEncoder,MinMaxScaler
mms=MinMaxScaler()
scaled=mms.fit_transform(df[['RRD1','RRD3','RRD4','RRD5','RRD6','RRD7','RRD8','RRD9','RRD10','RRD11','RRD12','RRD13','RRD14','RRD15','RRD16','RRD17','RRD18','RRD19','RRD20','RRD21','RRD22','RRD23','RRD24','RRD25','RRD26','RRD27','RRD28','RRD29','RRD30','RRD31','RRD32','RRD33','RRD34']])
scaled

ohe=OneHotEncoder(drop='first',sparse_output=False)
y=ohe.fit_transform(df[["Class"]])
y

y=y.reshape(-1)

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0,stratify=y)

from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
model=KNeighborsClassifier()
model.fit(X_train,y_train)
model.score(X_test,y_test)

model=LogisticRegression()
model.fit(X_train,y_train)
model.score(X_test,y_test)

"""# 43 BikeShareDay"""

from google.colab import files
files.upload()

df=pd.read_csv("Reg_BikeShareDay.csv")
df

df=df.drop(["instant","dteday"],axis=1)

from sklearn.preprocessing import MinMaxScaler
sc=MinMaxScaler()
X=sc.fit_transform(df[["season","yr","mnth","holiday","weekday","workingday","weathersit","temp","atemp","hum","windspeed","casual","registered","cnt"]])
X

from sklearn.decomposition import PCA
pca=PCA(n_components=2)
X_red=pca.fit_transform(X)
X_red

pd.DataFrame(X_red,columns=("col1","col2"))

col1=X_red[:,0]
col2=X_red[:,1]

import matplotlib.pyplot as plt
plt.scatter(col1,col2)

from sklearn.cluster import KMeans
model=KMeans(n_clusters=2)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")

elbow=[]
for k in range(1,15):
  model=KMeans(n_clusters=k)
  model.fit(X)
  elbow.append(model.inertia_)

elbow

plt.plot(range(1,15),elbow,color="red")
plt.scatter(range(1,15),elbow,color="green")

model=KMeans(n_clusters=3)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")
plt.scatter(col1[np.argwhere(cluster_l==2)],col2[np.argwhere(cluster_l==2)],color="blue")

plt.plot(col1,col2)

"""# 44 Journals"""

from google.colab import files
files.upload()

df=pd.read_csv("Journals.csv")
df

df=df.drop(["Unnamed: 0","title","publisher"],axis=1)

df.info()

X=df.iloc[:,:-1]
y=df.iloc[:,-1]

from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder,MinMaxScaler
sc=MinMaxScaler()
scaled=sc.fit_transform(df[["price","pages","charpp","citations","foundingyear","subs"]])
scaled

ohe=OneHotEncoder(drop='first',sparse_output=False)
OHE=ohe.fit_transform(df[["society"]])
OHE

oe=OrdinalEncoder()
y=oe.fit_transform(df[["field"]])
y

y=y.reshape(-1)

X=np.hstack((scaled,OHE))

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0,stratify=y)

from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
model=KNeighborsClassifier()
model.fit(X_train,y_train)
model.score(X_test,y_test)

model=LogisticRegression()
model.fit(X_train,y_train)
model.score(X_test,y_test)

"""# 45 BanknoteAuth"""

from google.colab import files
files.upload()

import numpy as np
import pandas as pd

df=pd.read_csv("Class_BanknoteAuth.csv")
df

X=df.drop(["Class"],axis=1)
y=df["Class"]

from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
X=sc.fit_transform(df[["Var","Skew","Kurt","Entropy"]])
X

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0,stratify=y)

from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
model=KNeighborsClassifier()
model.fit(X_train,y_train)
model.score(X_test,y_test)

model=LogisticRegression()
model.fit(X_train,y_train)
model.score(X_test,y_test)