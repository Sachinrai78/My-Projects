# -*- coding: utf-8 -*-
"""45 to 58 DataSets .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1l6bi2mBgJYtgnNbCXQ3K5I8cZ8IJi2Nb

# 46 Abalone
"""

from google.colab import files
files.upload()

import numpy as np
import pandas as pd

df=pd.read_csv("Class_Abalone.csv")
df

X=df.iloc[:,:-1]
y=df.iloc[:,-1]

df.info()

from sklearn.preprocessing import OneHotEncoder,StandardScaler,MinMaxScaler
ohe=OneHotEncoder(drop='first',sparse_output=False)
OHE=ohe.fit_transform(df[["Sex"]])
OHE

sc=StandardScaler()
scaler=sc.fit_transform(df[["Length","Diameter","Height","Whole_Weight","Shucked_Weight","Viscera_Weight","Shell_Weight"]])
scaler

X=np.hstack((OHE,scaler))

mms=MinMaxScaler()
y=mms.fit_transform(df[["Rings"]])
y

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)

from sklearn.neighbors import KNeighborsRegressor,KNeighborsClassifier
from sklearn.linear_model import LinearRegression
model=KNeighborsRegressor()
model.fit(X_train,y_train)
model.score(X_test,y_test)

model=LinearRegression()
model.fit(X_train,y_train)
model.score(X_test,y_test)

from sklearn.svm import SVR
model=SVR()
model.fit(X_train,y_train)
model.score(X_test,y_test)

from sklearn.linear_model import Lasso ,Ridge
model=Ridge()
model.fit(X_train,y_train)
model.score(X_test,y_test)

from sklearn.tree import DecisionTreeRegressor
model = DecisionTreeRegressor()
model.fit(X_train,y_train)
model.score(X_test,y_test)

"""# 47 Possum"""

import pandas as pd
import numpy as np
from google.colab import files
files.upload()

df=pd.read_csv("possum.csv")
df

df=df.drop(["case"],axis=1)

df.info()

a=df["footlgth"].mean()
df["footlgth"].fillna(a,inplace=True)

b=df["age"].mean()
df["age"].fillna(b,inplace=True)

df

df["Pop"].unique()

from sklearn.preprocessing import OneHotEncoder,StandardScaler
ohe=OneHotEncoder(drop='first',sparse_output=False)
OHE=ohe.fit_transform(df[["Pop","sex"]])
OHE

sc=StandardScaler()
scaler=sc.fit_transform(df[["age","hdlngth","skullw","totlngth","taill","footlgth","earconch","eye","chest","belly"]])
scaler

X=np.hstack((OHE,scaler))
X

from sklearn.decomposition import PCA
pca=PCA(n_components=2)
X_red=pca.fit_transform(X)
X_red

pd.DataFrame(X_red,columns=("col1","col2"))

col1=X_red[:,0]
col2=X_red[:,1]

import matplotlib.pyplot as plt
plt.scatter(col1,col2)

from sklearn.cluster import KMeans
model=KMeans(n_clusters=2)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")

elbow=[]
for k in range(1,15):
  model=KMeans(n_clusters=k)
  model.fit(X)
  elbow.append(model.inertia_)

elbow

plt.plot(range(1,15),elbow,color="red")
plt.scatter(range(1,15),elbow,color="green")

model=KMeans(n_clusters=3)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")
plt.scatter(col1[np.argwhere(cluster_l==2)],col2[np.argwhere(cluster_l==2)],color="blue")

plt.plot(col1,col2)

"""# 48 Adult"""

import pandas as pd
import numpy as np

from google.colab import files
files.upload()

df=pd.read_csv("adult.csv")
df.head(3)

X=df.iloc[:,:-1]
y=df.iloc[:,-1]

from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder,StandardScaler
ohe=OneHotEncoder(drop='first',sparse_output=False)
OHE=ohe.fit_transform(df[["gender","relationship","race"]])
OHE

oe=OrdinalEncoder()
OE=oe.fit_transform(df[["workclass","education","marital-status","occupation","native-country"]])
OE

sc=StandardScaler()
scaler=sc.fit_transform(df[["age","fnlwgt","educational-num","capital-gain","capital-loss","hours-per-week"]])
scaler

ohe=OneHotEncoder(drop='first',sparse_output=False)
y=ohe.fit_transform(df[["income"]])
y

y=y.reshape(-1)

X=np.hstack((OHE,OE,scaler))
X

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0,stratify=y)

from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
model=KNeighborsClassifier()
model.fit(X_train,y_train)
model.score(X_test,y_test)

model=LogisticRegression()
model.fit(X_train,y_train)
model.score(X_test,y_test)

"""#49 RealEstate"""

from google.colab import files
files.upload()

import pandas as pd
import numpy as np

df=pd.read_csv("realtor-data.csv")
df

df.info()

X=df.iloc[:,:-1]
y=df.iloc[:,-1]

df["city"].fillna("?",inplace=True)
df["prev_sold_date"].fillna("?",inplace=True)

from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder,MinMaxScaler
from sklearn.impute import SimpleImputer

imputer=SimpleImputer()
imp=imputer.fit_transform(df[["bed","bath","acre_lot","zip_code","house_size"]])
imp

ohe=OneHotEncoder(drop='first',sparse_output=False)
OHE=ohe.fit_transform(df[["status"]])
OHE

oe=OrdinalEncoder()
OE=oe.fit_transform(df[["city","state","prev_sold_date"]])
OE

mms=MinMaxScaler()
scaler=mms.fit_transform(imp)
scaler

X=np.hstack((scaler,OHE,OE))
X

mms=MinMaxScaler()
y=mms.fit_transform(df[["price"]])
y

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)

from sklearn.neighbors import KNeighborsRegressor

model=KNeighborsRegressor()
model.fit(X_train,y_train)
model.score(X_test,y_test)

"""#50 Aemf"""

from google.colab import files
files.upload()

import pandas as pd
import numpy as np

df=pd.read_csv("Aemf1.csv")
df

df.info()

from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder, MinMaxScaler
oe=OrdinalEncoder()
OE=oe.fit_transform(df[["City"]])
OE

ohe=OneHotEncoder(drop='first',sparse_output=False)
OHE=ohe.fit_transform(df[["Day","Room Type","Shared Room","Private Room","Superhost"]])
OHE

mms=MinMaxScaler()
scaled=mms.fit_transform(df[["Person Capacity","Multiple Rooms","Business","Cleanliness Rating","Guest Satisfaction","Bedrooms","City Center (km)","Metro Distance (km)","Attraction Index","Normalised Attraction Index","Restraunt Index","Normalised Restraunt Index"]])
scaled

X=np.hstack((OE,OHE,scaled))
X

from sklearn.decomposition import PCA
pca=PCA(n_components=2)
X_red=pca.fit_transform(X)
X_red

pd.DataFrame(X_red,columns=("col1","col2"))

col1=X_red[:,0]
col2=X_red[:,1]

import matplotlib.pyplot as plt
plt.scatter(col1,col2)

from sklearn.cluster import KMeans
model=KMeans(n_clusters=2)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")

elbow=[]
for k in range(1,15):
  model=KMeans(n_clusters=k)
  model.fit(X)
  elbow.append(model.inertia_)

elbow

plt.plot(range(1,15),elbow,color="red")
plt.scatter(range(1,15),elbow,color="green")

model=KMeans(n_clusters=3)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")
plt.scatter(col1[np.argwhere(cluster_l==2)],col2[np.argwhere(cluster_l==2)],color="blue")

plt.plot(col1,col2)

"""# 51 ATP Tennis"""

from google.colab import files
files.upload()

import numpy as np
import pandas as pd

df=pd.read_csv("atp_tennis.csv")
df

df=df.drop(["Tournament","Date"],axis=1)

X=df.iloc[:,:-1]
y=df.iloc[:,-1]

df["Score"].unique()

df.info()

from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder,MinMaxScaler
ohe=OneHotEncoder(drop='first',sparse_output=False)
OHE=ohe.fit_transform(df[["Court","Surface"]])
OHE

oe=OrdinalEncoder()
OE=oe.fit_transform(df[["Series","Round","Player_1","Player_2","Winner"]])
OE

mms=MinMaxScaler()
scaled=mms.fit_transform(df[["Best of","Rank_1","Rank_2","Pts_1","Pts_2","Odd_1","Odd_2"]])
scaled

X=np.hstack((OHE,OE,scaled))
X

oe=OrdinalEncoder()
y=oe.fit_transform(df[["Score"]])
y

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)

from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor
from sklearn.linear_model import LinearRegression,LogisticRegression

model=KNeighborsRegressor()
model.fit(X_train,y_train)
model.score(X_test,y_test)

df

X=np.hstack((OHE,OE,scaled,y))
X

from sklearn.decomposition import PCA
pca=PCA(n_components=2)
X_red=pca.fit_transform(X)
X_red

pd.DataFrame(X_red,columns=("col1","col2"))

col1=X_red[:,0]
col2=X_red[:,1]

import matplotlib.pyplot as plt
plt.scatter(col1,col2)

from sklearn.cluster import KMeans
model=KMeans(n_clusters=2)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")

elbow=[]
for k in range(1,15):
  model=KMeans(n_clusters=k)
  model.fit(X)
  elbow.append(model.inertia_)

elbow

plt.plot(range(1,15),elbow,color="red")
plt.scatter(range(1,15),elbow,color="green")

model=KMeans(n_clusters=3)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")
plt.scatter(col1[np.argwhere(cluster_l==2)],col2[np.argwhere(cluster_l==2)],color="blue")

plt.plot(col1,col2)

"""#52 Smoke Detection"""

import numpy as np
import pandas as pd
from google.colab import files
files.upload()

df=pd.read_csv("smoke_detection_iot.csv")
df

df=df.drop(["Unnamed: 0","UTC"],axis=1)

df.info()

X=df.iloc[:,:-1]
y=df.iloc[:,-1]

from sklearn.preprocessing import MinMaxScaler
mms=MinMaxScaler()
X=mms.fit_transform(df[["Temperature[C]","Humidity[%]","TVOC[ppb]","eCO2[ppm]","Raw H2","Raw Ethanol","Pressure[hPa]","PM1.0","PM2.5","NC0.5","NC1.0","NC2.5","CNT"]])
X

mms=MinMaxScaler()
y=mms.fit_transform(df[["Fire Alarm"]])
y

y=y.reshape(-1)

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)

from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor

model=KNeighborsRegressor()
model.fit(X_train,y_train)
model.score(X_test,y_test)

model=KNeighborsClassifier()
model.fit(X_train,y_train)
model.score(X_test,y_test)

"""#53 Credit Card"""

from google.colab import files
files.upload()

df=pd.read_csv("creditcard.csv")
df

X=df.iloc[:,:-1]
y=df.iloc[:,-1]

df["Class"].unique()

df.info()

from sklearn.preprocessing import MinMaxScaler

mms=MinMaxScaler()
X=mms.fit_transform(df[["Time","V1","V2","V3","V4","V5","V6","V7","V8","V9","V10","V11","V12","V13","V14","V15","V16","V17","V18","V19","V20","V21","V22","V23","V24","V25","V26","V27","V28","Amount"]])
X

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0,stratify=y)

from sklearn.neighbors import KNeighborsClassifier

model=KNeighborsClassifier()
model.fit(X_train,y_train)
model.score(X_test,y_test)

"""# 54 Air product"""

from google.colab import files
files.upload()

df=pd.read_csv("ai4i2020.csv")
df

df=df.drop(["UDI","Product ID"],axis=1)

df.info()

df["Type"].unique()

from sklearn.preprocessing import OneHotEncoder,MinMaxScaler
ohe=OneHotEncoder(drop='first',sparse_output=False)
OHE=ohe.fit_transform(df[["Type"]])
OHE

mms=MinMaxScaler()
scaled=mms.fit_transform(df[["Air temperature [K]","Process temperature [K]","Rotational speed [rpm]","Torque [Nm]","Tool wear [min]","Machine failure","TWF","HDF","PWF","OSF","RNF"]])
scaled

X=np.hstack((OHE,scaled))
X

from sklearn.decomposition import PCA
pca=PCA(n_components=2)
X_red=pca.fit_transform(X)
X_red

pd.DataFrame(X_red,columns=("col1","col2"))

col1=X_red[:,0]
col2=X_red[:,1]

import matplotlib.pyplot as plt
plt.scatter(col1,col2)

from sklearn.cluster import KMeans
model=KMeans(n_clusters=2)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")

elbow=[]
for k in range(1,15):
  model=KMeans(n_clusters=k)
  model.fit(X)
  elbow.append(model.inertia_)

elbow

plt.plot(range(1,15),elbow,color="red")
plt.scatter(range(1,15),elbow,color="green")

model=KMeans(n_clusters=3)
model.fit(X)
cluster_l=model.labels_
cluster_l

plt.scatter(col1[np.argwhere(cluster_l==0)],col2[np.argwhere(cluster_l==0)],color="red")
plt.scatter(col1[np.argwhere(cluster_l==1)],col2[np.argwhere(cluster_l==1)],color="green")
plt.scatter(col1[np.argwhere(cluster_l==2)],col2[np.argwhere(cluster_l==2)],color="blue")

plt.plot(col1,col2)

"""#55 NBA"""

from google.colab import files
files.upload()

df=pd.read_csv("nba_logreg.csv")
df

df.info()

df=df.drop(["Name"],axis=1)

X=df.iloc[:,:-1]
y=df.iloc[:,-1]

a=df["3P%"].mean()
df["3P%"].fillna(a,inplace=True)

from sklearn.preprocessing import MinMaxScaler
mms=MinMaxScaler()
X=mms.fit_transform(df[["GP","MIN","PTS","FGM","FGA","FG%","3P Made","3PA","3P%","FTA","FT%","OREB","DREB","REB","AST","STL","BLK","TOV"]])
X

mms=MinMaxScaler()
y=mms.fit_transform(df[["TARGET_5Yrs"]])
y

y=y.reshape(-1)

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0,stratify=y)

from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor
from sklearn.linear_model import LinearRegression, LogisticRegression

model=LogisticRegression()
model.fit(X_train,y_train)
model.score(X_test,y_test)

"""# 56 Fake News

"""

from google.colab import files
files.upload()

import numpy as np
import pandas as pd
df=pd.read_csv("FakeNewsNet.csv")
df

df.info()

df["news_url"].fillna("?",inplace=True)
df["source_domain"].fillna("?",inplace=True)

X=df.iloc[:,:-1]
y=df.iloc[:,-1]

from sklearn.preprocessing import OrdinalEncoder,MinMaxScaler
oe=OrdinalEncoder()
OE=oe.fit_transform(df[["title","news_url","source_domain"]])
OE

mms=MinMaxScaler()
scaled=mms.fit_transform(df[["tweet_num"]])
scaled

X=np.hstack((OE,scaled))
X

mms=MinMaxScaler()
y=mms.fit_transform(df[["real"]])
y

y=y.reshape(-1)

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0,stratify=y)

from sklearn.neighbors import KNeighborsClassifier

model=KNeighborsClassifier()
model.fit(X_train,y_train)
model.score(X_test,y_test)

"""#57 Mall Customers"""

from google.colab import files
files.upload()

import numpy as np
import pandas as pd
df=pd.read_csv("Mall_Customers.csv")
df

df=df.drop(["CustomerID"],axis=1)

X=df.iloc[:,:-1]
y=df.iloc[:,-1]

from sklearn.preprocessing import OneHotEncoder,MinMaxScaler
from sklearn.compose import ColumnTransformer, make_column_transformer

transformer= ColumnTransformer(transformers = [
    ("Encoding",OneHotEncoder(drop='first',sparse_output=False),["Genre"]),
    ("Scaling",MinMaxScaler(),["Age","Annual Income (k$)"])],remainder='passthrough'
)
model=KNeighborsRegressor()

transformer

from sklearn.pipeline import make_pipeline
pipe=make_pipeline(transformer)

pipe

X=pipe.fit_transform(X)

X

mms=MinMaxScaler()
y=mms.fit_transform(df[["Spending Score (1-100)"]])
y

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)

from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor
from sklearn.linear_model import LinearRegression, LogisticRegression

model=KNeighborsRegressor()
model.fit(X_train,y_train)
model.score(X_test,y_test)

"""#58 Dataset Project Power BI

"""

from google.colab import files
files.upload()

df=pd.read_csv("Datasetprojpowerbi.csv")
df

df.info()

X=df.iloc[:,:-1]
y=df.iloc[:,-1]

from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder,MinMaxScaler
from sklearn.compose import ColumnTransformer

transformer=ColumnTransformer(transformers=[
    ("Encoding",OrdinalEncoder(),["Genre","Reports"]),
    ("Scaling",MinMaxScaler(),["Age","Gpa","Year","Count"])],remainder="passthrough"
)
model=KNeighborsClassifier()

transformer

from sklearn.pipeline import make_pipeline
pipe=make_pipeline(transformer)

pipe

X=pipe.fit_transform(X)

X

ohe=OneHotEncoder(drop='first',sparse_output=False)
y=ohe.fit_transform(df[["Gender"]])
y

y=y.reshape(-1)

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0,stratify=y)

from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor
from sklearn.linear_model import LinearRegression, LogisticRegression
model=KNeighborsClassifier()
model.fit(X_train,y_train)
model.score(X_test,y_test)